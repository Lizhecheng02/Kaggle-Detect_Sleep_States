{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:00<00:00, 31187.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: [(5928, 13524), (23220, 30276), (40668, 47952), (75756, 82800), (178464, 186564), (196260, 203844), (230820, 241872), (248124, 255060)]\n",
      "           anglez      enmo      step\n",
      "0       38.906250  0.080322       0.0\n",
      "1       29.375000  0.075195       1.0\n",
      "2       37.218750  0.179077       2.0\n",
      "3       46.937500  0.092224       3.0\n",
      "4       60.500000  0.034210       4.0\n",
      "...           ...       ...       ...\n",
      "724135 -12.062500  0.038208  724135.0\n",
      "724136 -15.914062  0.025406  724136.0\n",
      "724137 -10.859375  0.028107  724137.0\n",
      "724138  -8.531250  0.027405  724138.0\n",
      "724139  -9.273438  0.032013  724139.0\n",
      "\n",
      "[724140 rows x 3 columns]\n",
      "<class 'list'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, SubsetRandomSampler, Subset\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "loaded_data = joblib.load(\"train_data.pkl\")\n",
    "\n",
    "targets, data, ids = loaded_data\n",
    "\n",
    "# 打印某个人的具体信息\n",
    "\n",
    "for i in tqdm(range(277)):\n",
    "    if ids[i] == \"03d92c9f6f8a\":\n",
    "        print(f\"Target: {targets[i]}\")\n",
    "        print(f\"{data[i]}\")\n",
    "        print(type(targets[i]))\n",
    "        print(type(data[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    window_overlap = 12\n",
    "    window_size = 12\n",
    "    train_ratio = 0.80\n",
    "    batch_size = 32\n",
    "    input_dim = 2\n",
    "    embed_dim = 32\n",
    "    num_classes = 4 \n",
    "    num_layers = 8\n",
    "    nhead = 4\n",
    "    dim_feedforward = 64\n",
    "    learning_rate = 1e-3\n",
    "    epochs = 300\n",
    "    train_record_steps = 140\n",
    "    test_record_steps = 20\n",
    "    dropout = 0.4\n",
    "    num_person = 300\n",
    "    scheduler_step_size = 20\n",
    "    scheduler_gamma = 0.8\n",
    "    fold = 8\n",
    "    weight_decay = 0.001\n",
    "    model_dir = \"./models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of total persons is: 277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/277 [01:04<1:37:27, 21.34s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\86183\\Desktop\\Lzc\\Data Science\\Kaggle Competition\\Kaggle - Detect Sleep States\\Train Code KFolds - Lzc.ipynb Cell 3\u001b[0m line \u001b[0;36m7\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/86183/Desktop/Lzc/Data%20Science/Kaggle%20Competition/Kaggle%20-%20Detect%20Sleep%20States/Train%20Code%20KFolds%20-%20Lzc.ipynb#W2sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/86183/Desktop/Lzc/Data%20Science/Kaggle%20Competition/Kaggle%20-%20Detect%20Sleep%20States/Train%20Code%20KFolds%20-%20Lzc.ipynb#W2sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/86183/Desktop/Lzc/Data%20Science/Kaggle%20Competition/Kaggle%20-%20Detect%20Sleep%20States/Train%20Code%20KFolds%20-%20Lzc.ipynb#W2sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m chunk \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49miloc[start:end][[\u001b[39m\"\u001b[39;49m\u001b[39manglez\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39menmo\u001b[39;49m\u001b[39m\"\u001b[39;49m]]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/86183/Desktop/Lzc/Data%20Science/Kaggle%20Competition/Kaggle%20-%20Detect%20Sleep%20States/Train%20Code%20KFolds%20-%20Lzc.ipynb#W2sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m chunk \u001b[39m=\u001b[39m chunk\u001b[39m.\u001b[39mto_numpy()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/86183/Desktop/Lzc/Data%20Science/Kaggle%20Competition/Kaggle%20-%20Detect%20Sleep%20States/Train%20Code%20KFolds%20-%20Lzc.ipynb#W2sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m \u001b[39mif\u001b[39;00m flag_empty \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\86183\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3773\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3770\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[0;32m   3771\u001b[0m     indexer \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mwhere(indexer)[\u001b[39m0\u001b[39m]\n\u001b[1;32m-> 3773\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_take_with_is_copy(indexer, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m   3775\u001b[0m \u001b[39mif\u001b[39;00m is_single_key:\n\u001b[0;32m   3776\u001b[0m     \u001b[39m# What does looking for a single key in a non-unique index return?\u001b[39;00m\n\u001b[0;32m   3777\u001b[0m     \u001b[39m# The behavior is inconsistent. It returns a Series, except when\u001b[39;00m\n\u001b[0;32m   3778\u001b[0m     \u001b[39m# - the key itself is repeated (test on data.shape, #9519), or\u001b[39;00m\n\u001b[0;32m   3779\u001b[0m     \u001b[39m# - we have a MultiIndex on columns (test on self.columns, #21309)\u001b[39;00m\n\u001b[0;32m   3780\u001b[0m     \u001b[39mif\u001b[39;00m data\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns, MultiIndex):\n\u001b[0;32m   3781\u001b[0m         \u001b[39m# GH#26490 using data[key] can cause RecursionError\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\86183\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:3948\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[1;34m(self, indices, axis)\u001b[0m\n\u001b[0;32m   3940\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_take_with_is_copy\u001b[39m(\u001b[39mself\u001b[39m: NDFrameT, indices, axis: Axis \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m NDFrameT:\n\u001b[0;32m   3941\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   3942\u001b[0m \u001b[39m    Internal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[0;32m   3943\u001b[0m \u001b[39m    attribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3946\u001b[0m \u001b[39m    See the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[0;32m   3947\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3948\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_take(indices\u001b[39m=\u001b[39;49mindices, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[0;32m   3949\u001b[0m     \u001b[39m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n\u001b[0;32m   3950\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m result\u001b[39m.\u001b[39m_get_axis(axis)\u001b[39m.\u001b[39mequals(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_axis(axis)):\n",
      "File \u001b[1;32mc:\\Users\\86183\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:3932\u001b[0m, in \u001b[0;36mNDFrame._take\u001b[1;34m(self, indices, axis, convert_indices)\u001b[0m\n\u001b[0;32m   3924\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   3925\u001b[0m         axis \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m   3926\u001b[0m         \u001b[39mand\u001b[39;00m indices\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   3927\u001b[0m         \u001b[39mand\u001b[39;00m using_copy_on_write()\n\u001b[0;32m   3928\u001b[0m         \u001b[39mand\u001b[39;00m is_range_indexer(indices, \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m))\n\u001b[0;32m   3929\u001b[0m     ):\n\u001b[0;32m   3930\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m-> 3932\u001b[0m new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mtake(\n\u001b[0;32m   3933\u001b[0m     indices,\n\u001b[0;32m   3934\u001b[0m     axis\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_block_manager_axis(axis),\n\u001b[0;32m   3935\u001b[0m     verify\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   3936\u001b[0m     convert_indices\u001b[39m=\u001b[39;49mconvert_indices,\n\u001b[0;32m   3937\u001b[0m )\n\u001b[0;32m   3938\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor(new_data)\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtake\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\86183\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py:963\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[1;34m(self, indexer, axis, verify, convert_indices)\u001b[0m\n\u001b[0;32m    960\u001b[0m     indexer \u001b[39m=\u001b[39m maybe_convert_indices(indexer, n, verify\u001b[39m=\u001b[39mverify)\n\u001b[0;32m    962\u001b[0m new_labels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes[axis]\u001b[39m.\u001b[39mtake(indexer)\n\u001b[1;32m--> 963\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreindex_indexer(\n\u001b[0;32m    964\u001b[0m     new_axis\u001b[39m=\u001b[39;49mnew_labels,\n\u001b[0;32m    965\u001b[0m     indexer\u001b[39m=\u001b[39;49mindexer,\n\u001b[0;32m    966\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m    967\u001b[0m     allow_dups\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    968\u001b[0m     copy\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    969\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\86183\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py:740\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[0;32m    737\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mRequested axis not found in manager\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    739\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 740\u001b[0m     new_blocks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_slice_take_blocks_ax0(\n\u001b[0;32m    741\u001b[0m         indexer,\n\u001b[0;32m    742\u001b[0m         fill_value\u001b[39m=\u001b[39;49mfill_value,\n\u001b[0;32m    743\u001b[0m         only_slice\u001b[39m=\u001b[39;49monly_slice,\n\u001b[0;32m    744\u001b[0m         use_na_proxy\u001b[39m=\u001b[39;49muse_na_proxy,\n\u001b[0;32m    745\u001b[0m     )\n\u001b[0;32m    746\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    747\u001b[0m     new_blocks \u001b[39m=\u001b[39m [\n\u001b[0;32m    748\u001b[0m         blk\u001b[39m.\u001b[39mtake_nd(\n\u001b[0;32m    749\u001b[0m             indexer,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    755\u001b[0m         \u001b[39mfor\u001b[39;00m blk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks\n\u001b[0;32m    756\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\86183\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py:898\u001b[0m, in \u001b[0;36mBaseBlockManager._slice_take_blocks_ax0\u001b[1;34m(self, slice_or_indexer, fill_value, only_slice, use_na_proxy)\u001b[0m\n\u001b[0;32m    896\u001b[0m                     blocks\u001b[39m.\u001b[39mappend(nb)\n\u001b[0;32m    897\u001b[0m             \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 898\u001b[0m                 nb \u001b[39m=\u001b[39m blk\u001b[39m.\u001b[39;49mtake_nd(taker, axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, new_mgr_locs\u001b[39m=\u001b[39;49mmgr_locs)\n\u001b[0;32m    899\u001b[0m                 blocks\u001b[39m.\u001b[39mappend(nb)\n\u001b[0;32m    901\u001b[0m \u001b[39mreturn\u001b[39;00m blocks\n",
      "File \u001b[1;32mc:\\Users\\86183\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:945\u001b[0m, in \u001b[0;36mBlock.take_nd\u001b[1;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[0;32m    942\u001b[0m     allow_fill \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    944\u001b[0m \u001b[39m# Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\u001b[39;00m\n\u001b[1;32m--> 945\u001b[0m new_values \u001b[39m=\u001b[39m algos\u001b[39m.\u001b[39;49mtake_nd(\n\u001b[0;32m    946\u001b[0m     values, indexer, axis\u001b[39m=\u001b[39;49maxis, allow_fill\u001b[39m=\u001b[39;49mallow_fill, fill_value\u001b[39m=\u001b[39;49mfill_value\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    949\u001b[0m \u001b[39m# Called from three places in managers, all of which satisfy\u001b[39;00m\n\u001b[0;32m    950\u001b[0m \u001b[39m#  these assertions\u001b[39;00m\n\u001b[0;32m    951\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ExtensionBlock):\n\u001b[0;32m    952\u001b[0m     \u001b[39m# NB: in this case, the 'axis' kwarg will be ignored in the\u001b[39;00m\n\u001b[0;32m    953\u001b[0m     \u001b[39m#  algos.take_nd call above.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\86183\\anaconda3\\lib\\site-packages\\pandas\\core\\array_algos\\take.py:117\u001b[0m, in \u001b[0;36mtake_nd\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39mtake(indexer, fill_value\u001b[39m=\u001b[39mfill_value, allow_fill\u001b[39m=\u001b[39mallow_fill)\n\u001b[0;32m    116\u001b[0m arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(arr)\n\u001b[1;32m--> 117\u001b[0m \u001b[39mreturn\u001b[39;00m _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)\n",
      "File \u001b[1;32mc:\\Users\\86183\\anaconda3\\lib\\site-packages\\pandas\\core\\array_algos\\take.py:162\u001b[0m, in \u001b[0;36m_take_nd_ndarray\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    157\u001b[0m     out \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(out_shape, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m    159\u001b[0m func \u001b[39m=\u001b[39m _get_take_nd_function(\n\u001b[0;32m    160\u001b[0m     arr\u001b[39m.\u001b[39mndim, arr\u001b[39m.\u001b[39mdtype, out\u001b[39m.\u001b[39mdtype, axis\u001b[39m=\u001b[39maxis, mask_info\u001b[39m=\u001b[39mmask_info\n\u001b[0;32m    161\u001b[0m )\n\u001b[1;32m--> 162\u001b[0m func(arr, indexer, out, fill_value)\n\u001b[0;32m    164\u001b[0m \u001b[39mif\u001b[39;00m flip_order:\n\u001b[0;32m    165\u001b[0m     out \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39mT\n",
      "File \u001b[1;32mc:\\Users\\86183\\anaconda3\\lib\\site-packages\\pandas\\core\\array_algos\\take.py:345\u001b[0m, in \u001b[0;36m_get_take_nd_function.<locals>.func\u001b[1;34m(arr, indexer, out, fill_value)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfunc\u001b[39m(arr, indexer, out, fill_value\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mnan) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    344\u001b[0m     indexer \u001b[39m=\u001b[39m ensure_platform_int(indexer)\n\u001b[1;32m--> 345\u001b[0m     _take_nd_object(\n\u001b[0;32m    346\u001b[0m         arr, indexer, out, axis\u001b[39m=\u001b[39;49maxis, fill_value\u001b[39m=\u001b[39;49mfill_value, mask_info\u001b[39m=\u001b[39;49mmask_info\n\u001b[0;32m    347\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\86183\\anaconda3\\lib\\site-packages\\pandas\\core\\array_algos\\take.py:528\u001b[0m, in \u001b[0;36m_take_nd_object\u001b[1;34m(arr, indexer, out, axis, fill_value, mask_info)\u001b[0m\n\u001b[0;32m    526\u001b[0m     arr \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mastype(out\u001b[39m.\u001b[39mdtype)\n\u001b[0;32m    527\u001b[0m \u001b[39mif\u001b[39;00m arr\u001b[39m.\u001b[39mshape[axis] \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 528\u001b[0m     arr\u001b[39m.\u001b[39;49mtake(indexer, axis\u001b[39m=\u001b[39;49maxis, out\u001b[39m=\u001b[39;49mout)\n\u001b[0;32m    529\u001b[0m \u001b[39mif\u001b[39;00m needs_masking:\n\u001b[0;32m    530\u001b[0m     outindexer \u001b[39m=\u001b[39m [\u001b[39mslice\u001b[39m(\u001b[39mNone\u001b[39;00m)] \u001b[39m*\u001b[39m arr\u001b[39m.\u001b[39mndim\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 生成放入模型的数据，假设使用30分钟作为一个窗口，那么需要找的为形状（360，2）的矩阵\n",
    "\n",
    "train_events = pd.read_csv(\"./train_events.csv\")\n",
    "num_person = len(train_events[\"series_id\"].unique())\n",
    "print(\"The number of total persons is:\", num_person)\n",
    "\n",
    "# 用来存储模型的输入与标签\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in tqdm(range(min(num_person, CFG.num_person))):\n",
    "\n",
    "    df = data[i]\n",
    "    pair_list = targets[i]\n",
    "    sleep_id = ids[i]\n",
    "\n",
    "    # 先提取出开始睡觉和结束睡觉的时间\n",
    "    onset_steps = []\n",
    "    wakeup_steps = []\n",
    "    for j in range(len(pair_list)):\n",
    "        onset_steps.append(pair_list[j][0])\n",
    "        wakeup_steps.append(pair_list[j][1])\n",
    "    # print(\"length of onset list:\", len(onset_steps))\n",
    "    # print(\"length of wakeup list:\", len(wakeup_steps))\n",
    "    # print(onset_steps)\n",
    "    # print(wakeup_steps)\n",
    "\n",
    "    # 中间没有明确时间点的区间全部都不要\n",
    "    empty_spaces = []\n",
    "    events = train_events[train_events[\"series_id\"] == sleep_id]\n",
    "    last_events = 0\n",
    "    mark = 0 \n",
    "    for (idx, row) in events.iterrows():\n",
    "        if np.isnan(row[\"step\"]):\n",
    "            mark = 1\n",
    "        else:\n",
    "            if row[\"step\"] > last_events and mark == 0:\n",
    "                last_events = row[\"step\"]\n",
    "            elif row[\"step\"] > last_events and mark == 1:\n",
    "                empty_spaces.append((int(last_events + CFG.window_size), int(row[\"step\"] - CFG.window_size)))\n",
    "                last_events = row[\"step\"]\n",
    "                mark = 0\n",
    "\n",
    "    # print(empty_spaces)\n",
    "\n",
    "    # 为训练数据设置label，如果区间中没有任何事件，标签为0，如果有开始睡觉事件，标签为1，如果有结束睡觉事件，标签为2\n",
    "    labels = []\n",
    "    for j in range(0, len(df), CFG.window_overlap):\n",
    "        start = j\n",
    "        if j + CFG.window_size >= len(df):\n",
    "            break\n",
    "        else:\n",
    "            end = j + CFG.window_size\n",
    "\n",
    "        flag_empty = 0\n",
    "        for k in empty_spaces:\n",
    "            if (k[0] <= start <= k[1]) or (k[0] <= end <= k[1]):\n",
    "                flag_empty = 1\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        flag_sleep = 0\n",
    "        for k in range(len(onset_steps)):\n",
    "            if (onset_steps[k] <= start < end <= wakeup_steps[k]):\n",
    "                flag_sleep = 1\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "\n",
    "        chunk = df.iloc[start:end][[\"anglez\", \"enmo\"]]\n",
    "        chunk = chunk.to_numpy()\n",
    "\n",
    "        if flag_empty == 1:\n",
    "            label = 4\n",
    "        elif any(start <= num <= end for num in wakeup_steps):\n",
    "            label = 3\n",
    "        elif any(start <= num <= end for num in onset_steps):\n",
    "            label = 2\n",
    "        elif flag_sleep == 1:\n",
    "            label = 1\n",
    "        else:\n",
    "            label = 0\n",
    "        labels.append(label)\n",
    "\n",
    "        if label != 4:\n",
    "            X.append(chunk)\n",
    "            y.append(label)\n",
    "\n",
    "    element_counts = Counter(labels)\n",
    "\n",
    "    # for element, count in element_counts.items():\n",
    "    #     print(f\"Element {element} occurs {count} times\")\n",
    "\n",
    "print(len(X), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_xingzhe = []\n",
    "y_xingzhe = []\n",
    "X_shuizhe = []\n",
    "y_shuizhe = []\n",
    "X_onset = []\n",
    "y_onset = []\n",
    "X_wakeup = []\n",
    "y_wakeup = []\n",
    "\n",
    "for i in tqdm(range(len(X))):\n",
    "    xi = X[i]\n",
    "    yi = y[i]\n",
    "    if yi == 0:\n",
    "        X_xingzhe.append(xi)\n",
    "        y_xingzhe.append(yi)\n",
    "    elif yi == 1:\n",
    "        X_shuizhe.append(xi)\n",
    "        y_shuizhe.append(yi)\n",
    "    elif yi == 2:\n",
    "        X_onset.append(xi)\n",
    "        y_onset.append(yi)\n",
    "    elif yi == 3:\n",
    "        X_wakeup.append(xi)\n",
    "        y_wakeup.append(yi)\n",
    "\n",
    "print(len(X_xingzhe), len(X_shuizhe), len(X_onset), len(X_wakeup))\n",
    "\n",
    "X_xingzhe = X_xingzhe[:max(len(X_onset), len(X_wakeup))]\n",
    "y_xingzhe = y_xingzhe[:max(len(X_onset), len(X_wakeup))]\n",
    "X_shuizhe = X_shuizhe[:max(len(X_onset), len(X_wakeup))]\n",
    "y_shuizhe = y_shuizhe[:max(len(X_onset), len(X_wakeup))]\n",
    "\n",
    "X = X_xingzhe + X_shuizhe + X_onset + X_wakeup\n",
    "y = y_xingzhe + y_shuizhe + y_onset + y_wakeup\n",
    "\n",
    "print(len(X), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, inputs, outputs):\n",
    "        self.inputs = inputs\n",
    "        self.outputs = outputs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        inp = self.inputs[index]\n",
    "        output = self.outputs[index]\n",
    "\n",
    "        input_tensor = torch.tensor(inp, dtype=torch.float32)\n",
    "        output_tensor = torch.tensor(output, dtype=torch.long)\n",
    "\n",
    "        return input_tensor, output_tensor\n",
    "\n",
    "\n",
    "dataset = MyDataset(X, y)\n",
    "print(len(dataset))\n",
    "\n",
    "# train_size = int(CFG.train_ratio * len(dataset))\n",
    "# test_size = len(dataset) - train_size\n",
    "\n",
    "# train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=CFG.batch_size, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=True)\n",
    "# print(len(train_loader), len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        embed_dim,\n",
    "        num_classes=3,\n",
    "        num_layers=8,\n",
    "        nhead=4,\n",
    "        dim_feedforward=64,\n",
    "        dropout=0.4\n",
    "    ):\n",
    "\n",
    "        super(TransformerModel, self).__init__()\n",
    "\n",
    "        self.conv1d = nn.Conv1d(\n",
    "            in_channels=input_dim, \n",
    "            out_channels=embed_dim, \n",
    "            kernel_size=3, \n",
    "            padding=1\n",
    "        )\n",
    "        self.embed_layer = nn.Linear(embed_dim, embed_dim)\n",
    "        self.layernorm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(\n",
    "                d_model=embed_dim,\n",
    "                nhead=nhead,\n",
    "                dim_feedforward=dim_feedforward,\n",
    "                dropout=dropout\n",
    "            ),\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "\n",
    "        self.classification = nn.Linear(embed_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.conv1d(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        x = self.embed_layer(x)\n",
    "        x = self.layernorm(x)\n",
    "        x = self.encoder(x.permute(1, 0, 2))\n",
    "        # print(x.shape)\n",
    "        x = x[-1]\n",
    "        x = self.classification(x)\n",
    "        return x\n",
    "\n",
    "# 示例\n",
    "model = TransformerModel(input_dim=2, embed_dim=32)\n",
    "input_data = torch.rand(3, 360, 2)\n",
    "output = model(input_data)\n",
    "print(model)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params}\")\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerModel(\n",
    "    input_dim=CFG.input_dim,\n",
    "    embed_dim=CFG.embed_dim,\n",
    "    num_classes=CFG.num_classes,\n",
    "    num_layers=CFG.num_layers,\n",
    "    nhead=CFG.nhead,\n",
    "    dim_feedforward=CFG.dim_feedforward,\n",
    "    dropout=CFG.dropout\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_step_losses = []\n",
    "test_losses = []\n",
    "test_step_losses = []\n",
    "learning_rates = []\n",
    "\n",
    "kf = KFold(n_splits=CFG.fold, shuffle=True, random_state=2023)\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(dataset)):\n",
    "    train_subset = Subset(dataset, train_index)\n",
    "    test_subset = Subset(dataset, test_index)\n",
    "\n",
    "    train_loader = DataLoader(train_subset, batch_size=CFG.batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_subset, batch_size=CFG.batch_size)\n",
    "\n",
    "    train_model = model.to(device=device)\n",
    "    train_model.train()\n",
    "\n",
    "    # init_lr = CFG.learning_rate\n",
    "\n",
    "    # if fold == 0:\n",
    "    #     optimizer = torch.optim.Adam(\n",
    "    #         model.parameters(),\n",
    "    #         lr=init_lr,\n",
    "    #         weight_decay=CFG.weight_decay\n",
    "    #     )\n",
    "    # else:\n",
    "    #     # current_learning_rate = optimizer.param_groups[0][\"lr\"]\n",
    "    #     # print(\"current learning rate is:\", current_learning_rate)\n",
    "    #     optimizer = torch.optim.Adam(\n",
    "    #         model.parameters(),\n",
    "    #         lr=init_lr / (1.25 ** fold),\n",
    "    #         weight_decay=CFG.weight_decay\n",
    "    #     )\n",
    "\n",
    "    optimizer = torch.optim.Adam(train_model.parameters(), lr=CFG.learning_rate)\n",
    "    scheduler = StepLR(optimizer, step_size=CFG.scheduler_step_size, gamma=CFG.scheduler_gamma)\n",
    "\n",
    "    min_loss = 10000.0\n",
    "\n",
    "    for epoch in range(1, CFG.epochs + 1):\n",
    "        train_loss = 0.0\n",
    "        test_loss = 0.0\n",
    "        train_step_loss = 0.0\n",
    "        test_step_loss = 0.0\n",
    "\n",
    "\n",
    "        learning_rate = optimizer.param_groups[0][\"lr\"]\n",
    "        learning_rates.append(learning_rate)\n",
    "\n",
    "        for batch_idx, (data, target) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            output = train_model(data)\n",
    "\n",
    "            loss = criterion(output, target)\n",
    "            train_loss += loss.item()\n",
    "            train_step_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (batch_idx + 1) % CFG.train_record_steps == 0:\n",
    "                train_step_loss /= CFG.train_record_steps\n",
    "                train_step_losses.append(train_step_loss)\n",
    "                print(f\"Fold: {fold + 1}, Epoch: {epoch + 1}, Step: {(batch_idx + 1) * CFG.train_record_steps}, Train Loss These Steps: {train_step_loss}\")\n",
    "                train_step_loss = 0.0\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in tqdm(enumerate(test_loader), total=len(test_loader)):\n",
    "                data = data.to(device)\n",
    "                target = target.to(device)\n",
    "                output = train_model(data)\n",
    "\n",
    "                loss = criterion(output, target)\n",
    "                test_loss += loss.item()\n",
    "                test_step_loss += loss.item()\n",
    "\n",
    "                if (batch_idx + 1) % CFG.test_record_steps == 0:\n",
    "                    test_step_loss /= CFG.test_record_steps\n",
    "                    test_step_losses.append(test_step_loss)\n",
    "                    print(f\"Fold: {fold + 1}, Epoch: {epoch + 1}, Step: {(batch_idx + 1) * CFG.test_record_steps}, Test Loss These Steps: {test_step_loss}\")\n",
    "                    test_step_loss = 0.0\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        test_loss /= len(test_loader)\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "        if test_loss < min_loss:\n",
    "            min_loss = test_loss\n",
    "            torch.save(train_model.state_dict(), f\"{CFG.model_dir}/model_{fold + 1}.pth\")\n",
    "\n",
    "\n",
    "        print(f\"Fold: {fold + 1}, Epoch: {epoch}, Train Loss: {train_loss}, Test Loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.plot(test_losses, label=\"Test Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Train & Test Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(train_step_losses, label=\"Train Step Loss\")\n",
    "plt.plot(test_step_losses, label=\"Test Step Loss\")\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Train & Test Step Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(learning_rates)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "\n",
    "plt.savefig(\"plot.png\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
