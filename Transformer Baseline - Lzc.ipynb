{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, SubsetRandomSampler, Subset\n",
    "\n",
    "loaded_data = joblib.load(\"train_data.pkl\")\n",
    "\n",
    "targets, data, ids = loaded_data\n",
    "\n",
    "# 打印某个人的具体信息\n",
    "\n",
    "for i in tqdm(range(277)):\n",
    "    if ids[i] == \"44a41bba1ee7\":\n",
    "        print(f\"Target: {targets[i]}\")\n",
    "        print(f\"{data[i]}\")\n",
    "        print(type(targets[i]))\n",
    "        print(type(data[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    window_overlap = 30\n",
    "    window_size = 60\n",
    "    train_ratio = 0.8\n",
    "    batch_size = 32\n",
    "    input_dim = 2\n",
    "    embed_dim = 32\n",
    "    num_classes = 3 \n",
    "    num_layers = 6\n",
    "    nhead = 4\n",
    "    dim_feedforward = 64\n",
    "    learning_rate = 1e-3\n",
    "    epochs = 5\n",
    "    train_record_steps = 80\n",
    "    test_record_steps = 20\n",
    "    num_person = 277"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成放入模型的数据，假设使用30分钟作为一个窗口，那么需要找的为形状（360，2）的矩阵\n",
    "\n",
    "train_events = pd.read_csv(\"./train_events.csv\")\n",
    "num_person = len(train_events[\"series_id\"].unique())\n",
    "print(\"The number of total persons is:\", num_person)\n",
    "\n",
    "# 用来存储模型的输入与标签\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in tqdm(range(min(num_person, CFG.num_person))):\n",
    "\n",
    "    df = data[i]\n",
    "    pair_list = targets[i]\n",
    "    sleep_id = ids[i]\n",
    "\n",
    "    # 先提取出开始睡觉和结束睡觉的时间\n",
    "    onset_steps = []\n",
    "    wakeup_steps = []\n",
    "    for j in range(len(pair_list)):\n",
    "        onset_steps.append(pair_list[j][0])\n",
    "        wakeup_steps.append(pair_list[j][1])\n",
    "    # print(\"length of onset list:\", len(onset_steps))\n",
    "    # print(\"length of wakeup list:\", len(wakeup_steps))\n",
    "    # print(onset_steps)\n",
    "    # print(wakeup_steps)\n",
    "\n",
    "    # 中间没有明确时间点的区间全部都不要\n",
    "    empty_spaces = []\n",
    "    events = train_events[train_events[\"series_id\"] == sleep_id]\n",
    "    last_events = 0\n",
    "    mark = 0 \n",
    "    for (idx, row) in events.iterrows():\n",
    "        if np.isnan(row[\"step\"]):\n",
    "            mark = 1\n",
    "        else:\n",
    "            if row[\"step\"] > last_events and mark == 0:\n",
    "                last_events = row[\"step\"]\n",
    "            elif row[\"step\"] > last_events and mark == 1:\n",
    "                empty_spaces.append((int(last_events + 720), int(row[\"step\"] - 720)))\n",
    "                last_events = row[\"step\"]\n",
    "                mark = 0\n",
    "\n",
    "    # print(empty_spaces)\n",
    "\n",
    "    # 为训练数据设置label，如果区间中没有任何事件，标签为0，如果有开始睡觉事件，标签为1，如果有结束睡觉事件，标签为2\n",
    "    labels = []\n",
    "    for j in range(0, len(df), CFG.window_overlap):\n",
    "        start = j\n",
    "        if j + CFG.window_size >= len(df):\n",
    "            break\n",
    "        else:\n",
    "            end = j + CFG.window_size\n",
    "\n",
    "        flag = 0\n",
    "        for k in empty_spaces:\n",
    "            if (k[0] <= start <= k[1]) or (k[0] <= end <= k[1]):\n",
    "                flag = 1\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        chunk = df.iloc[start:end][[\"anglez\", \"enmo\"]]\n",
    "        chunk = chunk.to_numpy()\n",
    "\n",
    "        if flag == 1:\n",
    "            label = 3\n",
    "        elif any(start <= num <= end for num in wakeup_steps):\n",
    "            label = 2\n",
    "        elif any(start <= num <= end for num in onset_steps):\n",
    "            label = 1\n",
    "        else:\n",
    "            label = 0\n",
    "        labels.append(label)\n",
    "\n",
    "        if label != 3:\n",
    "            X.append(chunk)\n",
    "            y.append(label)\n",
    "\n",
    "    element_counts = Counter(labels)\n",
    "\n",
    "    for element, count in element_counts.items():\n",
    "        print(f'Element {element} occurs {count} times')\n",
    "\n",
    "print(len(X), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_noevent = []\n",
    "y_noevent = []\n",
    "X_onset = []\n",
    "y_onset = []\n",
    "X_wakeup = []\n",
    "y_wakeup = []\n",
    "\n",
    "for i in tqdm(range(len(X))):\n",
    "    xi = X[i]\n",
    "    yi = y[i]\n",
    "    if yi == 0:\n",
    "        X_noevent.append(xi)\n",
    "        y_noevent.append(yi)\n",
    "    elif yi == 1:\n",
    "        X_onset.append(xi)\n",
    "        y_onset.append(yi)\n",
    "    elif yi == 2:\n",
    "        X_wakeup.append(xi)\n",
    "        y_wakeup.append(yi)\n",
    "\n",
    "print(len(X_noevent), len(X_onset), len(X_wakeup))\n",
    "\n",
    "X_noevent = X_noevent[:10400]\n",
    "y_noevent = y_noevent[:10400]\n",
    "X = X_noevent + X_onset + X_wakeup\n",
    "y = y_noevent + y_onset + y_wakeup\n",
    "\n",
    "print(len(X), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, inputs, outputs):\n",
    "        self.inputs = inputs\n",
    "        self.outputs = outputs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        inp = self.inputs[index]\n",
    "        output = self.outputs[index]\n",
    "\n",
    "        input_tensor = torch.tensor(inp, dtype=torch.float32)\n",
    "        output_tensor = torch.tensor(output, dtype=torch.long)\n",
    "\n",
    "        return input_tensor, output_tensor\n",
    "\n",
    "\n",
    "dataset = MyDataset(X, y)\n",
    "print(len(dataset))\n",
    "\n",
    "train_size = int(CFG.train_ratio * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=CFG.batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=True)\n",
    "print(len(train_loader), len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        embed_dim,\n",
    "        num_classes=3,\n",
    "        num_layers=8,\n",
    "        nhead=4,\n",
    "        dim_feedforward=64\n",
    "    ):\n",
    "\n",
    "        super(TransformerModel, self).__init__()\n",
    "\n",
    "        self.embed_layer = nn.Linear(input_dim, embed_dim)\n",
    "        self.layernorm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(\n",
    "                d_model=embed_dim,\n",
    "                nhead=nhead,\n",
    "                dim_feedforward=dim_feedforward,\n",
    "            ),\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "\n",
    "        self.classification = nn.Linear(embed_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embed_layer(x)\n",
    "        x = self.layernorm(x)\n",
    "        x = self.encoder(x.permute(1, 0, 2))\n",
    "        x = x[-1]\n",
    "        x = self.classification(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = TransformerModel(input_dim=2, embed_dim=32)\n",
    "input_data = torch.rand(3, 360, 2)\n",
    "output = model(input_data)\n",
    "print(model)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params}\")\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerModel(\n",
    "    input_dim=CFG.input_dim,\n",
    "    embed_dim=CFG.embed_dim,\n",
    "    num_classes=CFG.num_classes,\n",
    "    num_layers=CFG.num_layers,\n",
    "    nhead=CFG.nhead,\n",
    "    dim_feedforward=CFG.dim_feedforward\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=CFG.learning_rate)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "train_losses = []\n",
    "train_step_losses = []\n",
    "test_losses = []\n",
    "test_step_losses = []\n",
    "\n",
    "for epoch in range(1, CFG.epochs + 1):\n",
    "    train_loss = 0.0\n",
    "    test_loss = 0.0\n",
    "    train_step_loss = 0.0\n",
    "    test_step_loss = 0.0\n",
    "\n",
    "    for batch_idx, (data, target) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        output = model(data)\n",
    "\n",
    "        loss = criterion(output, target)\n",
    "        train_loss += loss.item()\n",
    "        train_step_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (batch_idx + 1) % CFG.train_record_steps == 0:\n",
    "            train_step_loss /= CFG.train_record_steps\n",
    "            train_step_losses.append(train_step_loss)\n",
    "            print(f\"Step: {(batch_idx + 1) * CFG.train_record_steps}, Train Loss These Steps: {train_step_loss}\")\n",
    "            train_step_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in tqdm(enumerate(test_loader), total=len(test_loader)):\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            output = model(data)\n",
    "\n",
    "            loss = criterion(output, target)\n",
    "            test_loss += loss.item()\n",
    "            test_step_loss += loss.item()\n",
    "\n",
    "            if (batch_idx + 1) % CFG.test_record_steps == 0:\n",
    "                test_step_loss /= CFG.test_record_steps\n",
    "                test_step_losses.append(test_step_loss)\n",
    "                print(f\"Step: {(batch_idx + 1) * CFG.test_record_steps}, Test Loss These Steps: {test_step_loss}\")\n",
    "                test_step_loss = 0.0\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "    print(f\"Epoch: {epoch}, Train Loss: {train_loss}, Test Loss: {test_loss}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
